
R version 3.6.0 (2019-04-26) -- "Planting of a Tree"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-redhat-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #read in data
> library(tidyverse)
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ ggplot2 3.3.2     ✔ purrr   0.3.4
✔ tibble  3.0.4     ✔ dplyr   1.0.2
✔ tidyr   1.1.2     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
> full_train <- read_csv("data/train.csv",
+                        col_types = cols(.default = col_guess(), 
+                                         calc_admn_cd = col_character()))  %>% 
+   select(-classification)
> 
> #str(full_train)
> 
> set.seed(500)
> # import fall membership report data and clean 
> 
> sheets <- readxl::excel_sheets("data/fallmembershipreport_20192020.xlsx")
> ode_schools <- readxl::read_xlsx("data/fallmembershipreport_20192020.xlsx", sheet = sheets[4])
> str(ode_schools)
tibble [1,459 × 33] (S3: tbl_df/tbl/data.frame)
 $ Attending District Institution ID          : num [1:1459] 2063 2113 2113 1899 2252 ...
 $ District Name                              : chr [1:1459] "Adel SD 21" "Adrian SD 61" "Adrian SD 61" "Alsea SD 7J" ...
 $ Attending School ID                        : num [1:1459] 498 707 708 17 1208 ...
 $ School Name                                : chr [1:1459] "Adel Elementary School" "Adrian Elementary School" "Adrian High School" "Alsea Charter School" ...
 $ 2018-19 Total Enrollment                   : chr [1:1459] "8" "206" "89" "226" ...
 $ 2019-20 Total Enrollment                   : chr [1:1459] "7" "203" "89" "321" ...
 $ 2019-20 American Indian/Alaska Native      : chr [1:1459] "2" "0" "1" "5" ...
 $ 2019-20 % American Indian/Alaska Native    : num [1:1459] 0.2857 0 0.0112 0.0156 0.024 ...
 $ 2019-20 Asian                              : chr [1:1459] "0" "0" "1" "18" ...
 $ 2019-20 % Asian                            : num [1:1459] 0 0 0.0112 0.0561 0 ...
 $ 2019-20 Native Hawaiian/ Pacific Islander  : chr [1:1459] "0" "0" "0" "0" ...
 $ 2019-20 % Native Hawaiian/ Pacific Islander: num [1:1459] 0 0 0 0 0 0 0 0 0 0 ...
 $ 2019-20 Black/African American             : chr [1:1459] "0" "0" "0" "2" ...
 $ 2019-20 % Black/African American           : num [1:1459] 0 0 0 0.00623 0.00601 0 0 0.0303 0 0 ...
 $ 2019-20 Hispanic/ Latino                   : chr [1:1459] "0" "45" "15" "28" ...
 $ 2019-20 % Hispanic/ Latino                 : num [1:1459] 0 0.2217 0.1685 0.0872 0.1441 ...
 $ 2019-20 White                              : chr [1:1459] "5" "157" "70" "253" ...
 $ 2019-20 % White                            : num [1:1459] 0.714 0.773 0.787 0.788 0.766 ...
 $ 2019-20 Multiracial                        : chr [1:1459] "0" "1" "2" "15" ...
 $ 2019-20 % Multiracial                      : num [1:1459] 0 0.00493 0.02247 0.04673 0.06006 ...
 $ 2019-20 Kindergarten                       : chr [1:1459] "0" "24" "0" "16" ...
 $ 2019-20 Grade One                          : chr [1:1459] "0" "20" "0" "10" ...
 $ 2019-20 Grade Two                          : chr [1:1459] "0" "17" "0" "15" ...
 $ 2019-20 Grade Three                        : chr [1:1459] "0" "19" "0" "16" ...
 $ 2019-20 Grade Four                         : chr [1:1459] "1" "21" "0" "11" ...
 $ 2019-20 Grade Five                         : chr [1:1459] "0" "17" "0" "18" ...
 $ 2019-20 Grade Six                          : chr [1:1459] "1" "26" "0" "17" ...
 $ 2019-20 Grade Seven                        : chr [1:1459] "3" "29" "0" "21" ...
 $ 2019-20 Grade Eight                        : chr [1:1459] "2" "30" "0" "17" ...
 $ 2019-20 Grade Nine                         : chr [1:1459] "0" "0" "22" "27" ...
 $ 2019-20 Grade Ten                          : chr [1:1459] "0" "0" "27" "49" ...
 $ 2019-20 Grade Eleven                       : chr [1:1459] "0" "0" "20" "38" ...
 $ 2019-20 Grade Twelve                       : chr [1:1459] "0" "0" "20" "66" ...
> 
> ethnicities <- ode_schools %>% select(attnd_schl_inst_id = `Attending School ID`,
+                                       sch_name = `School Name`,
+                                       contains("%")) %>%
+   janitor::clean_names()
> 
> names(ethnicities) <- gsub("x2019_20_percent", "p", names(ethnicities))
> 
> head(ethnicities)
# A tibble: 6 x 9
  attnd_schl_inst… sch_name p_american_indi… p_asian p_native_hawaii…
             <dbl> <chr>               <dbl>   <dbl>            <dbl>
1              498 Adel El…          0.286    0                     0
2              707 Adrian …          0        0                     0
3              708 Adrian …          0.0112   0.0112                0
4               17 Alsea C…          0.0156   0.0561                0
5             1208 Amity E…          0.0240   0                     0
6             1210 Amity H…          0.00794  0.0119                0
# … with 4 more variables: p_black_african_american <dbl>,
#   p_hispanic_latino <dbl>, p_white <dbl>, p_multiracial <dbl>
> 
> 
> #make ethnicities have attnd_schl_inst_id as a unique identifier - clunky, but works!
> ethnicities <- ethnicities %>%
+   group_by(attnd_schl_inst_id) %>%
+   summarize(p_american_indian_alaska_native = mean(p_american_indian_alaska_native),
+             p_asian = mean(p_asian),
+             p_native_hawaiian_pacific_islander = mean(p_native_hawaiian_pacific_islander),
+             p_black_african_american = mean(p_black_african_american),
+             p_hispanic_latino = mean(p_hispanic_latino),
+             p_white = mean(p_white),
+             p_multiracial = mean(p_multiracial))
`summarise()` ungrouping output (override with `.groups` argument)
> 
> 
> #Join ethnicity data and training data
> full_train <- left_join(full_train, ethnicities)
Joining, by = "attnd_schl_inst_id"
> 
> #dim(full_train)
> 
> # import tidied frl and student count data 
> frl <- read_csv("data/frl_stucounts.csv")

── Column specification ────────────────────────────────────────────────────────
cols(
  ncessch = col_double(),
  free_lunch_qualified = col_double(),
  reduced_price_lunch_qualified = col_double(),
  missing = col_double(),
  not_applicable = col_double(),
  no_category_codes = col_double(),
  n = col_double()
)

> 
> # add frl data to train data
> frl_fulltrain <- left_join(full_train, frl)
Joining, by = "ncessch"
> 
> #dim(frl_fulltrain)
> 
> #split data and resample
> 
> library(tidymodels)
── Attaching packages ────────────────────────────────────── tidymodels 0.1.1 ──
✔ broom     0.7.1      ✔ recipes   0.1.14
✔ dials     0.0.9      ✔ rsample   0.0.8 
✔ infer     0.5.3      ✔ tune      0.1.1 
✔ modeldata 0.0.2      ✔ workflows 0.2.1 
✔ parsnip   0.1.3      ✔ yardstick 0.0.7 
── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
✖ scales::discard() masks purrr::discard()
✖ dplyr::filter()   masks stats::filter()
✖ recipes::fixed()  masks stringr::fixed()
✖ dplyr::lag()      masks stats::lag()
✖ yardstick::spec() masks readr::spec()
✖ recipes::step()   masks stats::step()
> 
> set.seed(7895)
> edu_split <- initial_split(frl_fulltrain)
> train <- training(edu_split)
> test <- testing(edu_split)
> train_cv <- vfold_cv(train, strata = "score", v = 2)
> 
> str(train_cv)
tibble [2 × 2] (S3: vfold_cv/rset/tbl_df/tbl/data.frame)
 $ splits:List of 2
  ..$ :List of 4
  .. ..$ data  : tibble [142,070 × 52] (S3: tbl_df/tbl/data.frame)
  .. .. ..$ id                                : num [1:142070] 1 3 5 7 12 17 18 21 22 23 ...
  .. .. ..$ gndr                              : chr [1:142070] "F" "M" "F" "F" ...
  .. .. ..$ ethnic_cd                         : chr [1:142070] "H" "M" "H" "H" ...
  .. .. ..$ attnd_dist_inst_id                : num [1:142070] 2142 1995 2053 1964 1924 ...
  .. .. ..$ attnd_schl_inst_id                : num [1:142070] 1330 3400 1773 191 84 ...
  .. .. ..$ enrl_grd                          : num [1:142070] 6 8 8 8 8 8 8 8 8 8 ...
  .. .. ..$ calc_admn_cd                      : chr [1:142070] NA NA NA NA ...
  .. .. ..$ tst_bnch                          : chr [1:142070] "G6" "3B" "3B" "3B" ...
  .. .. ..$ tst_dt                            : chr [1:142070] "5/14/2018 0:00:00" "5/1/2018 0:00:00" "5/1/2018 0:00:00" "5/22/2018 0:00:00" ...
  .. .. ..$ migrant_ed_fg                     : chr [1:142070] "N" "N" "Y" "N" ...
  .. .. ..$ ind_ed_fg                         : chr [1:142070] "N" "N" "N" "N" ...
  .. .. ..$ sp_ed_fg                          : chr [1:142070] "Y" "N" "N" "N" ...
  .. .. ..$ tag_ed_fg                         : chr [1:142070] "N" "N" "N" "N" ...
  .. .. ..$ econ_dsvntg                       : chr [1:142070] "Y" "N" "Y" "Y" ...
  .. .. ..$ ayp_lep                           : chr [1:142070] "X" NA "F" "E" ...
  .. .. ..$ stay_in_dist                      : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ stay_in_schl                      : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ dist_sped                         : chr [1:142070] "N" "N" "N" "N" ...
  .. .. ..$ trgt_assist_fg                    : chr [1:142070] "N" "N" "N" "N" ...
  .. .. ..$ ayp_dist_partic                   : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ ayp_schl_partic                   : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ ayp_dist_prfrm                    : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ ayp_schl_prfrm                    : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ rc_dist_partic                    : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ rc_schl_partic                    : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ rc_dist_prfrm                     : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ rc_schl_prfrm                     : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ partic_dist_inst_id               : num [1:142070] 2142 1995 2053 1964 1924 ...
  .. .. ..$ partic_schl_inst_id               : num [1:142070] 1330 3400 1773 191 84 ...
  .. .. ..$ lang_cd                           : chr [1:142070] NA NA NA NA ...
  .. .. ..$ tst_atmpt_fg                      : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ grp_rpt_dist_partic               : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ grp_rpt_schl_partic               : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ grp_rpt_dist_prfrm                : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ grp_rpt_schl_prfrm                : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ score                             : num [1:142070] 2340 2551 2529 2417 2515 ...
  .. .. ..$ ncessch                           : num [1:142070] 4.11e+11 4.10e+11 4.11e+11 4.10e+11 4.11e+11 ...
  .. .. ..$ lat                               : num [1:142070] 44.9 43 44.6 43.2 45.4 ...
  .. .. ..$ lon                               : num [1:142070] -123 -124 -121 -124 -123 ...
  .. .. ..$ p_american_indian_alaska_native   : num [1:142070] 0.00186 0.00463 0.10316 0.016 0.0048 ...
  .. .. ..$ p_asian                           : num [1:142070] 0.00931 0 0.01053 0 0.02278 ...
  .. .. ..$ p_native_hawaiian_pacific_islander: num [1:142070] 0.04562 0 0.00632 0.00267 0.01319 ...
  .. .. ..$ p_black_african_american          : num [1:142070] 0.01117 0 0.00632 0.00267 0.03357 ...
  .. .. ..$ p_hispanic_latino                 : num [1:142070] 0.6536 0.0741 0.499 0.1067 0.3118 ...
  .. .. ..$ p_white                           : num [1:142070] 0.242 0.819 0.366 0.749 0.528 ...
  .. .. ..$ p_multiracial                     : num [1:142070] 0.03631 0.10185 0.00842 0.12267 0.08633 ...
  .. .. ..$ free_lunch_qualified              : num [1:142070] 813 124 327 142 373 253 446 140 144 405 ...
  .. .. ..$ reduced_price_lunch_qualified     : num [1:142070] 85 23 28 21 79 59 91 46 27 65 ...
  .. .. ..$ missing                           : num [1:142070] 0 0 0 0 0 0 0 0 0 0 ...
  .. .. ..$ not_applicable                    : num [1:142070] 0 0 0 0 0 0 0 0 0 0 ...
  .. .. ..$ no_category_codes                 : num [1:142070] 898 147 355 163 452 312 537 186 171 470 ...
  .. .. ..$ n                                 : num [1:142070] 1952 223 882 321 1387 ...
  .. ..$ in_id : int [1:71034] 1 3 6 8 12 19 20 21 23 28 ...
  .. ..$ out_id: logi NA
  .. ..$ id    : tibble [1 × 1] (S3: tbl_df/tbl/data.frame)
  .. .. ..$ id: chr "Fold1"
  .. ..- attr(*, "class")= chr [1:2] "rsplit" "vfold_split"
  ..$ :List of 4
  .. ..$ data  : tibble [142,070 × 52] (S3: tbl_df/tbl/data.frame)
  .. .. ..$ id                                : num [1:142070] 1 3 5 7 12 17 18 21 22 23 ...
  .. .. ..$ gndr                              : chr [1:142070] "F" "M" "F" "F" ...
  .. .. ..$ ethnic_cd                         : chr [1:142070] "H" "M" "H" "H" ...
  .. .. ..$ attnd_dist_inst_id                : num [1:142070] 2142 1995 2053 1964 1924 ...
  .. .. ..$ attnd_schl_inst_id                : num [1:142070] 1330 3400 1773 191 84 ...
  .. .. ..$ enrl_grd                          : num [1:142070] 6 8 8 8 8 8 8 8 8 8 ...
  .. .. ..$ calc_admn_cd                      : chr [1:142070] NA NA NA NA ...
  .. .. ..$ tst_bnch                          : chr [1:142070] "G6" "3B" "3B" "3B" ...
  .. .. ..$ tst_dt                            : chr [1:142070] "5/14/2018 0:00:00" "5/1/2018 0:00:00" "5/1/2018 0:00:00" "5/22/2018 0:00:00" ...
  .. .. ..$ migrant_ed_fg                     : chr [1:142070] "N" "N" "Y" "N" ...
  .. .. ..$ ind_ed_fg                         : chr [1:142070] "N" "N" "N" "N" ...
  .. .. ..$ sp_ed_fg                          : chr [1:142070] "Y" "N" "N" "N" ...
  .. .. ..$ tag_ed_fg                         : chr [1:142070] "N" "N" "N" "N" ...
  .. .. ..$ econ_dsvntg                       : chr [1:142070] "Y" "N" "Y" "Y" ...
  .. .. ..$ ayp_lep                           : chr [1:142070] "X" NA "F" "E" ...
  .. .. ..$ stay_in_dist                      : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ stay_in_schl                      : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ dist_sped                         : chr [1:142070] "N" "N" "N" "N" ...
  .. .. ..$ trgt_assist_fg                    : chr [1:142070] "N" "N" "N" "N" ...
  .. .. ..$ ayp_dist_partic                   : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ ayp_schl_partic                   : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ ayp_dist_prfrm                    : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ ayp_schl_prfrm                    : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ rc_dist_partic                    : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ rc_schl_partic                    : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ rc_dist_prfrm                     : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ rc_schl_prfrm                     : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ partic_dist_inst_id               : num [1:142070] 2142 1995 2053 1964 1924 ...
  .. .. ..$ partic_schl_inst_id               : num [1:142070] 1330 3400 1773 191 84 ...
  .. .. ..$ lang_cd                           : chr [1:142070] NA NA NA NA ...
  .. .. ..$ tst_atmpt_fg                      : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ grp_rpt_dist_partic               : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ grp_rpt_schl_partic               : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ grp_rpt_dist_prfrm                : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ grp_rpt_schl_prfrm                : chr [1:142070] "Y" "Y" "Y" "Y" ...
  .. .. ..$ score                             : num [1:142070] 2340 2551 2529 2417 2515 ...
  .. .. ..$ ncessch                           : num [1:142070] 4.11e+11 4.10e+11 4.11e+11 4.10e+11 4.11e+11 ...
  .. .. ..$ lat                               : num [1:142070] 44.9 43 44.6 43.2 45.4 ...
  .. .. ..$ lon                               : num [1:142070] -123 -124 -121 -124 -123 ...
  .. .. ..$ p_american_indian_alaska_native   : num [1:142070] 0.00186 0.00463 0.10316 0.016 0.0048 ...
  .. .. ..$ p_asian                           : num [1:142070] 0.00931 0 0.01053 0 0.02278 ...
  .. .. ..$ p_native_hawaiian_pacific_islander: num [1:142070] 0.04562 0 0.00632 0.00267 0.01319 ...
  .. .. ..$ p_black_african_american          : num [1:142070] 0.01117 0 0.00632 0.00267 0.03357 ...
  .. .. ..$ p_hispanic_latino                 : num [1:142070] 0.6536 0.0741 0.499 0.1067 0.3118 ...
  .. .. ..$ p_white                           : num [1:142070] 0.242 0.819 0.366 0.749 0.528 ...
  .. .. ..$ p_multiracial                     : num [1:142070] 0.03631 0.10185 0.00842 0.12267 0.08633 ...
  .. .. ..$ free_lunch_qualified              : num [1:142070] 813 124 327 142 373 253 446 140 144 405 ...
  .. .. ..$ reduced_price_lunch_qualified     : num [1:142070] 85 23 28 21 79 59 91 46 27 65 ...
  .. .. ..$ missing                           : num [1:142070] 0 0 0 0 0 0 0 0 0 0 ...
  .. .. ..$ not_applicable                    : num [1:142070] 0 0 0 0 0 0 0 0 0 0 ...
  .. .. ..$ no_category_codes                 : num [1:142070] 898 147 355 163 452 312 537 186 171 470 ...
  .. .. ..$ n                                 : num [1:142070] 1952 223 882 321 1387 ...
  .. ..$ in_id : int [1:71036] 2 4 5 7 9 10 11 13 14 15 ...
  .. ..$ out_id: logi NA
  .. ..$ id    : tibble [1 × 1] (S3: tbl_df/tbl/data.frame)
  .. .. ..$ id: chr "Fold2"
  .. ..- attr(*, "class")= chr [1:2] "rsplit" "vfold_split"
 $ id    : chr [1:2] "Fold1" "Fold2"
 - attr(*, "v")= num 2
 - attr(*, "repeats")= num 1
 - attr(*, "strata")= logi TRUE
> 
> #create recipe and prep
> rec <- recipe(score ~., train) %>%
+   step_mutate(tst_dt = lubridate::mdy_hms(tst_dt),
+               time_index = as.numeric(tst_dt)) %>%
+   step_rm(contains("bnch")) %>%
+   update_role(tst_dt, new_role = "time_index") %>%
+   update_role(contains("id"), ncessch, new_role = "id") %>% #removed sch_name
+   step_novel(all_nominal(), -all_outcomes()) %>%
+   step_unknown(all_nominal(), -all_outcomes()) %>%
+   step_rollimpute(all_numeric(), -all_outcomes(), -has_role("id"), -n) %>%
+   step_medianimpute(all_numeric(), -all_outcomes(), -has_role("id")) %>%
+   step_nzv(all_predictors(), freq_cut = 0, unique_cut = 0) %>%
+   step_dummy(all_nominal(), -has_role(match = "id"), -all_outcomes(), -time_index) %>%
+   step_nzv(all_predictors()) %>%
+   step_interact(terms = ~ starts_with('lat'):starts_with("lon"))
> 
> prep(rec)
Data Recipe

Inputs:

       role #variables
         id          6
    outcome          1
  predictor         44
 time_index          1

Training data contained 142070 data points and 142070 incomplete rows. 

Operations:

Variable mutation for tst_dt, time_index [trained]
Variables removed tst_bnch [trained]
Novel factor level assignment for gndr, ethnic_cd, calc_admn_cd, ... [trained]
Unknown factor level assignment for gndr, ethnic_cd, calc_admn_cd, ... [trained]
Rolling Imputation for enrl_grd, lat, ... [trained]
Median Imputation for enrl_grd, lat, ... [trained]
Sparse, unbalanced variable filter removed calc_admn_cd, missing, not_applicable [trained]
Dummy variables from gndr, ethnic_cd, migrant_ed_fg, ind_ed_fg, ... [trained]
Sparse, unbalanced variable filter removed 85 items [trained]
Interactions with lat:lon [trained]
> 
> #create random forest tuning model
> cores <- 8
> 
> rf_def_mod <- rand_forest() %>%
+   set_engine("ranger",
+              num.threads = cores,
+              importance = "permutation",
+              verbose = TRUE) %>%
+   set_mode("regression")
> 
> rf_tune_mod <- rf_def_mod %>%
+   set_args(
+     mtry = tune(),
+     trees = tune(),
+     min_n = tune()
+   )
> 
> translate(rf_tune_mod)
Random Forest Model Specification (regression)

Main Arguments:
  mtry = tune()
  trees = tune()
  min_n = tune()

Engine-Specific Arguments:
  num.threads = cores
  importance = permutation
  verbose = TRUE

Computational engine: ranger 

Model fit template:
ranger::ranger(formula = missing_arg(), data = missing_arg(), 
    case.weights = missing_arg(), mtry = tune(), num.trees = tune(), 
    min.node.size = tune(), num.threads = cores, importance = "permutation", 
    verbose = TRUE, seed = sample.int(10^5, 1))
> 
> #create workflow, set metrics
> rf_tune_wflow <- workflow() %>%
+   add_recipe(rec) %>%
+   add_model(rf_tune_mod)
> 
> metrics_eval <- metric_set(rmse, 
+                            rsq, 
+                            huber_loss)
> 
> #create grid
> rf_grid_reg <- grid_regular(
+   mtry(c(5, 5)),
+   trees(c(1323, 1323)),
+   min_n(range = c(30, 60)),
+   levels = c(1, 1, 20))
>   
> #fit the tuning model
> rf_grid_res <- tune_grid(
+   rf_tune_wflow,
+   train_cv,
+   grid = rf_grid_reg,
+   metrics = metrics_eval, #from above - same metrics of rsq, rmse, huber_loss
+   control = control_resamples(verbose = TRUE,
+                               save_pred = TRUE,
+                               extract = function(x) extract_model(x)))
i Fold1: recipe
✓ Fold1: recipe
i Fold1: model  1/20
✓ Fold1: model  1/20
i Fold1: model  1/20 (predictions)
i Fold1: model  2/20
✓ Fold1: model  2/20
i Fold1: model  2/20 (predictions)
i Fold1: model  3/20
✓ Fold1: model  3/20
i Fold1: model  3/20 (predictions)
i Fold1: model  4/20
✓ Fold1: model  4/20
i Fold1: model  4/20 (predictions)
i Fold1: model  5/20
✓ Fold1: model  5/20
i Fold1: model  5/20 (predictions)
i Fold1: model  6/20
✓ Fold1: model  6/20
i Fold1: model  6/20 (predictions)
i Fold1: model  7/20
✓ Fold1: model  7/20
i Fold1: model  7/20 (predictions)
i Fold1: model  8/20
✓ Fold1: model  8/20
i Fold1: model  8/20 (predictions)
i Fold1: model  9/20
✓ Fold1: model  9/20
i Fold1: model  9/20 (predictions)
i Fold1: model 10/20
✓ Fold1: model 10/20
i Fold1: model 10/20 (predictions)
i Fold1: model 11/20
✓ Fold1: model 11/20
i Fold1: model 11/20 (predictions)
i Fold1: model 12/20
✓ Fold1: model 12/20
i Fold1: model 12/20 (predictions)
i Fold1: model 13/20
✓ Fold1: model 13/20
i Fold1: model 13/20 (predictions)
i Fold1: model 14/20
✓ Fold1: model 14/20
i Fold1: model 14/20 (predictions)
i Fold1: model 15/20
✓ Fold1: model 15/20
i Fold1: model 15/20 (predictions)
i Fold1: model 16/20
✓ Fold1: model 16/20
i Fold1: model 16/20 (predictions)
i Fold1: model 17/20
✓ Fold1: model 17/20
i Fold1: model 17/20 (predictions)
i Fold1: model 18/20
✓ Fold1: model 18/20
i Fold1: model 18/20 (predictions)
i Fold1: model 19/20
✓ Fold1: model 19/20
i Fold1: model 19/20 (predictions)
i Fold1: model 20/20
✓ Fold1: model 20/20
i Fold1: model 20/20 (predictions)
i Fold2: recipe
✓ Fold2: recipe
i Fold2: model  1/20
✓ Fold2: model  1/20
i Fold2: model  1/20 (predictions)
i Fold2: model  2/20
✓ Fold2: model  2/20
i Fold2: model  2/20 (predictions)
i Fold2: model  3/20
✓ Fold2: model  3/20
i Fold2: model  3/20 (predictions)
i Fold2: model  4/20
✓ Fold2: model  4/20
i Fold2: model  4/20 (predictions)
i Fold2: model  5/20
✓ Fold2: model  5/20
i Fold2: model  5/20 (predictions)
i Fold2: model  6/20
✓ Fold2: model  6/20
i Fold2: model  6/20 (predictions)
i Fold2: model  7/20
✓ Fold2: model  7/20
i Fold2: model  7/20 (predictions)
i Fold2: model  8/20
✓ Fold2: model  8/20
i Fold2: model  8/20 (predictions)
i Fold2: model  9/20
✓ Fold2: model  9/20
i Fold2: model  9/20 (predictions)
i Fold2: model 10/20
✓ Fold2: model 10/20
i Fold2: model 10/20 (predictions)
i Fold2: model 11/20
✓ Fold2: model 11/20
i Fold2: model 11/20 (predictions)
i Fold2: model 12/20
✓ Fold2: model 12/20
i Fold2: model 12/20 (predictions)
i Fold2: model 13/20
✓ Fold2: model 13/20
i Fold2: model 13/20 (predictions)
i Fold2: model 14/20
✓ Fold2: model 14/20
i Fold2: model 14/20 (predictions)
i Fold2: model 15/20
✓ Fold2: model 15/20
i Fold2: model 15/20 (predictions)
i Fold2: model 16/20
✓ Fold2: model 16/20
i Fold2: model 16/20 (predictions)
i Fold2: model 17/20
✓ Fold2: model 17/20
i Fold2: model 17/20 (predictions)
i Fold2: model 18/20
✓ Fold2: model 18/20
i Fold2: model 18/20 (predictions)
i Fold2: model 19/20
✓ Fold2: model 19/20
i Fold2: model 19/20 (predictions)
i Fold2: model 20/20
✓ Fold2: model 20/20
i Fold2: model 20/20 (predictions)
> 
> saveRDS(rf_grid_res, "RFTuneTalapasGrid.Rds")
> 
> #collect metrics
> rf_grid_met <- rf_grid_res %>%
+   collect_metrics() 
> 
> rf_grid_rsq <- rf_grid_met %>%
+   filter(.metric == "rsq") %>%
+   arrange(.metric, desc(mean)) %>%
+   slice(1:5)
> 
> rf_grid_rmse <- rf_grid_met %>%
+   filter(.metric == "rmse") %>%
+   arrange(.metric, mean) %>%
+   slice(1:5)
> 
> rf_grid_hl <- rf_grid_met %>%
+   filter(.metric == "huber_loss") %>%
+   arrange(.metric, mean) %>%
+   slice(1:5)
> 
> rf_grid_metrics <- rbind(rf_grid_rsq, rf_grid_rmse, rf_grid_hl) 
> 
> rf_grid_metrics %>%
+   write.csv("./RFTuneMetricsGrid.csv", row.names = FALSE)
> 
> #look at plot of tuned metrics:
> rf_grid_res %>%
+   autoplot() +
+   geom_line()
> 
> #save plot for use on blog:
> 
> ggsave("RFTunedMetricsGrid.pdf",
+        plot = last_plot(),
+        scale = 1)
Saving 7 x 7 in image
> 
> #select best results, based on rmse:
> rf_best <- select_best(rf_grid_res, metric = "rmse")
> 
> #finalize our work flow based on this best result:
> 
> rf_wf_final <- finalize_workflow(
+   rf_tune_wflow,
+   rf_best)
> 
> 
> #make predictions on test.csv using this final workflow
> full_test <- read_csv("data/test.csv",
+                       col_types = cols(.default = col_guess(), 
+                                        calc_admn_cd = col_character()))
> #str(full_test)
> 
> #join with ethnicity data
> full_test_eth <- left_join(full_test, ethnicities) #join with FRL dataset
Joining, by = "attnd_schl_inst_id"
> #str(full_test_eth)
> 
> #join with frl
> full_test_FRL <- left_join(full_test_eth, frl)
Joining, by = "ncessch"
> 
> nrow(full_test_FRL)
[1] 63142
> 
> #workflow
> fit_workflow <- fit(rf_wf_final, frl_fulltrain)
Growing trees.. Progress: 43%. Estimated remaining time: 41 seconds.
Growing trees.. Progress: 86%. Estimated remaining time: 10 seconds.
Computing permutation importance.. Progress: 36%. Estimated remaining time: 54 seconds.
Computing permutation importance.. Progress: 73%. Estimated remaining time: 22 seconds.
> 
> #use model to make predictions for test dataset
> preds_final <- predict(fit_workflow, full_test_FRL) #use model to make predictions for test dataset
> 
> saveRDS(preds_final, "RFPreds.Rds")
> 
> head(preds_final)
# A tibble: 6 x 1
  .pred
  <dbl>
1 2515.
2 2524.
3 2663.
4 2432.
5 2516.
6 2488.
> 
> pred_frame <- tibble(Id = full_test_FRL$id, Predicted = preds_final$.pred)
> head(pred_frame, 20)
# A tibble: 20 x 2
      Id Predicted
   <dbl>     <dbl>
 1     4     2515.
 2     6     2524.
 3     8     2663.
 4     9     2432.
 5    11     2516.
 6    15     2488.
 7    19     2395.
 8    20     2472.
 9    32     2463.
10    33     2404.
11    40     2604.
12    42     2418.
13    46     2513.
14    50     2544.
15    57     2542.
16    59     2471.
17    66     2622.
18    73     2551.
19    78     2441.
20    91     2410.
> nrow(pred_frame)
[1] 63142
> 
> #create prediction file
> write_csv(pred_frame, "fit_rf.csv")
> 
> 
> 
> 
> 
>   
> 
> 
> 
> proc.time()
     user    system   elapsed 
16247.019    81.906  2825.375 
